{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843896bf-ce46-4465-9a37-f405d32b5e58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64b7fd29-9ccb-450f-bfd4-4e95e766ba68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "strStorageAccountName=\"sa27septshivam\"\n",
    "strContainerName=\"input\"\n",
    "strSource=\"wasbs://\"+strContainerName+\"@\"+strStorageAccountName+\".blob.core.windows.net/\"\n",
    "strMountPoint=\"/mnt/mp6\"\n",
    "strKey=\"fs.azure.account.key.\"+strStorageAccountName+\".blob.core.windows.net\"\n",
    "strValue=\"IE+gG81sqVN8mS8TvBOB4IYobCP1YemnlSaBveZP51oy3hYhhvgGRuK7COO6mWrYBWHFWrEoE/od+AStp3uxZA==\"\n",
    "\n",
    "result=dbutils.fs.mount(\n",
    "    source=strSource,\n",
    "    mount_point=strMountPoint,\n",
    "    extra_configs={strKey:strValue}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8012667-d8f6-4c72-a336-00c02aa7ec0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/mp6/movies.csv</td><td>movies.csv</td><td>5073</td><td>1695795853000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/mp6/movies.csv",
         "movies.csv",
         5073,
         1695795853000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /mnt/mp6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4540c5a1-38f2-4b69-aa83-87d5c298d884",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-535448656308862>, line 8\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m strKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.key.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mstrStorageAccountName\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      6\u001B[0m strValue\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmA1TPq1q0UMABp/wW+BR3eFpzro7MEyYKcWOSUItwpgTYvdbfv1i4cJEMG4I1h9pbFb5rw/cpNEuL+AStVJY5mg==\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 8\u001B[0m result\u001B[38;5;241m=\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\n",
       "\u001B[1;32m      9\u001B[0m     source\u001B[38;5;241m=\u001B[39mstrSource,\n",
       "\u001B[1;32m     10\u001B[0m     mount_point\u001B[38;5;241m=\u001B[39mstrMountPoint,\n",
       "\u001B[1;32m     11\u001B[0m     extra_configs\u001B[38;5;241m=\u001B[39m{strKey:strValue}\n",
       "\u001B[1;32m     12\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:346\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf_with_exception_handling\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m    345\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 346\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    349\u001B[0m         \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mExecutionError\u001B[39;00m(\u001B[38;5;167;01mException\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:451\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.mount\u001B[0;34m(self, source, mount_point, encryption_type, owner, extra_configs)\u001B[0m\n",
       "\u001B[1;32m    447\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_types([(owner, string_types)])\n",
       "\u001B[1;32m    448\u001B[0m java_extra_configs \u001B[38;5;241m=\u001B[39m \\\n",
       "\u001B[1;32m    449\u001B[0m     MapConverter()\u001B[38;5;241m.\u001B[39mconvert(extra_configs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msc\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39m_gateway_client)\n",
       "\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_return(\n",
       "\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdbcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmount\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmount_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencryption_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mowner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjava_extra_configs\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:194\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    190\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    192\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    193\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m: Unsupported Azure Scheme: abfss"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)\nFile \u001B[0;32m<command-535448656308862>, line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m strKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.key.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mstrStorageAccountName\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m strValue\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmA1TPq1q0UMABp/wW+BR3eFpzro7MEyYKcWOSUItwpgTYvdbfv1i4cJEMG4I1h9pbFb5rw/cpNEuL+AStVJY5mg==\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m result\u001B[38;5;241m=\u001B[39mdbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\n\u001B[1;32m      9\u001B[0m     source\u001B[38;5;241m=\u001B[39mstrSource,\n\u001B[1;32m     10\u001B[0m     mount_point\u001B[38;5;241m=\u001B[39mstrMountPoint,\n\u001B[1;32m     11\u001B[0m     extra_configs\u001B[38;5;241m=\u001B[39m{strKey:strValue}\n\u001B[1;32m     12\u001B[0m )\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:346\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf_with_exception_handling\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    345\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 346\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    349\u001B[0m         \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mExecutionError\u001B[39;00m(\u001B[38;5;167;01mException\u001B[39;00m):\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:451\u001B[0m, in \u001B[0;36mDBUtils.FSHandler.mount\u001B[0;34m(self, source, mount_point, encryption_type, owner, extra_configs)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_types([(owner, string_types)])\n\u001B[1;32m    448\u001B[0m java_extra_configs \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m    449\u001B[0m     MapConverter()\u001B[38;5;241m.\u001B[39mconvert(extra_configs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msc\u001B[38;5;241m.\u001B[39m_jvm\u001B[38;5;241m.\u001B[39m_gateway_client)\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_return(\n\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdbcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmount\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmount_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencryption_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mowner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjava_extra_configs\u001B[49m\u001B[43m)\u001B[49m)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:194\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    190\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 194\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mIllegalArgumentException\u001B[0m: Unsupported Azure Scheme: abfss",
       "errorSummary": "<span class='ansi-red-fg'>IllegalArgumentException</span>: Unsupported Azure Scheme: abfss",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "strStorageAccountName=\"sa27septgen2shivam\"\n",
    "strContainerName=\"input\"\n",
    "strSource=\"abfss://\"+strContainerName+\"@\"+strStorageAccountName+\".dfs.core.windows.net/\"\n",
    "strMountPoint=\"/mnt/mp8\"\n",
    "strKey=\"fs.azure.account.key.\"+strStorageAccountName+\".dfs.core.windows.net\"\n",
    "strValue=\"mA1TPq1q0UMABp/wW+BR3eFpzro7MEyYKcWOSUItwpgTYvdbfv1i4cJEMG4I1h9pbFb5rw/cpNEuL+AStVJY5mg==\"\n",
    "\n",
    "result=dbutils.fs.mount(\n",
    "    source=strSource,\n",
    "    mount_point=strMountPoint,\n",
    "    extra_configs={strKey:strValue}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7518986d-45cb-4ba1-9066-745cec736080",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 535448656308861,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook_Mounting",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
